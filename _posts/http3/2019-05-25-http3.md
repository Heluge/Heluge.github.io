---
title: Nouveautés introduites par HTTP/3
date: 2019-05-25 00:00:00 +01:00
---

# HTTP/3


HTTP/3 est la prochaine version majeure du Hypertexte Transfer Protocol qui succédera au HTTP/2. Cette nouvelle version repose sur les mêmes principes que HTTP/1 et HTTP/2 mais utilise un protocole de transport différent. Le but de ce changement est de rendre les échanges internet plus rapides et de résoudre les problèmes de pertes de paquets de manière plus performante.

## Background / limites de l’HTTP/2

Pour comprendre ce qui a motivé le développement d’une nouvelle version HTTP, il faut connaître l'évolution de ce protocole. L’HTTP comme nous le connaissons aujourd’hui a été créé en 1996 avec le HTTP/1. Une nouvelle connexion était créée à chaque nouvel échange entre serveur et client. La création d’une connexion étant un processus coûteux, le temps de latence était donc très long pour chaque page. En plus de cela, une fois la connexion établie, il y a un temps d’attente nommé le “slow start” qui permet à l’algorithme de congestion de déterminer la quantité de données qui peut être simultanément sur le réseau sans créer de congestion. Cela évite de bloquer le réseau en lui envoyant des paquets qu'il ne peut pas gérer mais cela retarde également l'envoi d’un paquet.

La version HTTP/1.1 cherchait à corriger ce problème en mettant en place la concept de “keep-alive”. Lorsqu’une connexion est en “keep-alive” cela signifie que la connexion doit être réutilisée pour les futurs échanges, cela évite donc d’avoir à refaire le processus relativement long de création d’une connexion.
Les sites se sont mis à évoluer et à contenir plus d’informations, qui ne pouvaient pas tenir dans une seule requête. Une des solutions à ce problème était de paralléliser les requêtes venant d’une même origine mais sur des connexions différentes. Par exemple, lors d’une navigation internet, les différents fichiers d’un site sont envoyés simultanément sur 3 connexions différentes. Cela fait gagner du temps mais le concept de keep-alive perd son utilité puisqu'il faut créer plusieurs connexions pour un même échange. 

Plus tard est apparu HTTP/2 qui a introduit le principe de multiplexage. C’est-à-dire que plusieurs requêtes peuvent être faites sur la même connexion TCP. Par exemple, lorsqu’on essaye d'accéder à une page web, on a besoin d'accéder à plusieurs fichiers: des images, un fichier CSS, javascript etc… Il faut donc effectuer plusieurs requêtes. Le multiplexage permet d'effectuer ces requêtes dans la même connexion. Ce qui permet au navigateur d’afficher toutes les données du site simultanément. 

![img](https://lh6.googleusercontent.com/Y8k8S44hLu7qSQ6JOA9C715sBOT5trC9-sJZRSalDe33brEJtfNiCSx8AvLmuTQ3iGQb0MJscITJq8Gn3BwZ62rXri2IdeDqxeR8ZMCFBEBDKHlgXBsOK0zC7zqleXk97su_-hIr)

Bien qu'elle permette de réduire le temps de latence, le multiplexage est limité par le TCP. En effet, à son niveau, TCP n’est pas capable de séparer les différents flux de données, c’est un protocole de transport et non d’application. Donc lorsqu’un des flux multiplexés subit une perte de paquet, c’est toute la connexion qui est bloquée jusqu’à ce que TCP fasse son travail de récupération de paquet. Cela signifie que tous les paquets, même s’ils sont déjà transmis et en attente, sont bloqués dans le tampon du nœud de destination jusqu’à ce que le paquet perdu soit retransmis.

## Les améliorations de HTTP/3

La grande amélioration du HTTP/3 est l’utilisation d’un nouveau protocole de transport appelé QUIC pour Quick UDP Internet Connection, contrairement au HTTP/2 qui utilise TCP. Comme son nom l’indique, QUIC repose sur un protocole de transport déjà existant: l’UDP.

L’avantage du UDP par rapport au TCP est sa rapidité. Le TCP a besoin de faire plusieurs allers-retours pour diffuser des données. Il est orienté « connexion ». C'est-à-dire, lorsqu’une machine A envoie des données à une machine B, la machine A doit d’abord établir une connexion avec le destinataire puis lui envoyer les données et finalement la machine B répond par un accusé réception. Ce système a un avantage parce qu’il renforce la sécurité: il permet de savoir si le destinataire a bien reçu tous les paquets dans le bon ordre et sans être corrompu. Par contre, **il est assez lent** puisqu’il doit faire plusieurs allers-retours.

**L’UDP**, au contraire, est un protocole orienté « non connexion ». Lorsqu’une machine A envoie des paquets à une machine B, le flux est unidirectionnel. La machine B n’est pas prévenue de l’arrivée des données et elle les reçoit sans avoir à envoyer d’accusé de réception.
Le but du protocole QUIC (*Quick UDP Internet Connections*) c’est de conserver les avantages de l’UDP qui est plus léger que le TCP, tout en comblant l'absence de fiabilité de l’UDP.

![img](https://lh6.googleusercontent.com/6R4bidm9vGAATqoC22qhpc1UOLtExXyJlG0QbWSNJa0NJqLYDat9N7EWLYQYP1xQIysYuBMdwcCP1EZvlg1GibzEyyk_0lafDsvFJ99-BIoDrjTkbbsJnVk8i2xWoA3DETyE13ld)

## Comment QUIC résout ces problèmes

### Connexion

Comme expliqué précédemment, TCP repose sur un système de connexion. Pour démarrer une connexion, il doit y avoir un "handshake” entre le client et le serveur. À chaque fois qu’un utilisateur accède à une page web avec HTTPS, il y a un handshake. Cet échange doit respecter la norme du protocole TLS qui sert notamment à définir le mode de chiffrement à utiliser pour la communication. QUIC a mis en place un système de connexion qui est assez similaire à celui du TCP tout en réduisant le temps du handshake.
Avec QUIC, la demande de connexion et de chiffrement auprès du serveurs se fait en une seule fois (ce qui demande plusieurs allers-retours au TCP). Plutôt que d’avoir plusieurs échanges au début de la connexion pour définir le mode de chiffrement de la communication, QUIC envoie les certificats et les clés nécessaires à la sécurité dans le premier paquet. Ce qui enlève donc le besoin d’avoir une négociation sur le protocole de sécurité. 

Sur ce schéma on peut voir les différentes étapes du handshake et d’une requête d’un côté pour TCP + TLS/1.3 et de l’autre la nouvelle version avec QUIC. On peut voir que le handshake en TCP se compose de 2 aller-retour alors que du côté de QUIC, il n’en suffit que d’un.

![img](https://lh6.googleusercontent.com/nNrc_6DgyiOe-4Du4CYvALDo87U3gvWvFTKsH7KDqbH1qhjKSKI4qIyYsrgyNk8WJ4nfDC17LmoSlzF9gJ6_KenAjyM-FTVkQfh0ypu-zFFg_6blXlAlpaJJVa3-kpvCXJdIgyeX)

### Perte de paquet

Le deuxième problème que QUIC a réussi à résoudre est la gestion de perte de paquet. UDP n'a pas de fonction qui permette de vérifier si un paquet a bien été reçu, QUIC s’est donc inspiré du système de TCP de gestion de paquet.

**QUIC n’a pas le problème d'HTTP/2 pour le multiplexage.** QUIC encapsule les paquets au-dessus de la couche UDP, ce qui permet à UDP de faire une séparation entre chaque flux. Chaque flux est donc contrôlé séparément et chaque paquet perdu est retransmis au niveau de QUIC et non de UDP. Ça veut dire que si une erreur apparaît dans un flux, les autres flux peuvent continuer à être envoyés indépendamment.

### Chiffrement individuel des paquets

QUIC inclut également d’autres changements qui améliorent la latence. Par exemple, les paquets sont chiffrés individuellement. Il n’y a donc pas besoin d’attendre le reste des paquets pour chiffrer la communication. Cette amélioration n’est pas possible en TCP puisque le protocole de chiffrement chiffre le flux dans son ensemble et n’est pas au courant des délimitations des paquets des couches supérieures. 

### Changement de réseau

Un autre objectif qu’avait QUIC était d’améliorer les performances lors d’un changement de réseau, c’est à dire lorsqu’un utilisateur mobile, par exemple, passe d’une connexion wifi à un réseau mobile. Lorsque ça arrive en TCP, une longue procédure commence où chaque connexion existante expire une par une et est ensuite rétablie par une demande. Pour corriger ce problème, QUIC inclut un identifiant de connexion pour chaque connexion au serveur, indépendamment de la source. Ça permet à la connexion d’être rétablie par le simple envoie d’un paquet avec toujours le même ID de connexion qui sera toujours valide même si l’utilisateur change d’adresse IP.

## Pourquoi changer le protocole HTTP ? 

Nous avons vu que la grande nouveauté d’HTTP/3 concernait la couche transport. Mais s’il s’agit seulement d’un changement de transport, ne peut-on pas continuer à utiliser l’HTTP/2 avec QUIC ? Pourquoi aurait-on besoin d’un nouveau protocole d’application ? 

Il y a tout de même quelques changements à considérer du côté de l’application. Il est vrai que certaines caractéristiques de l’HTTP/2 peuvent être associées à QUIC très facilement mais ce n’est pas le cas de toutes. Par exemple, l’algorithme de compression d’HTTP/2 nommé HPACK dépend fortement de l’ordre dans lequel les différentes requêtes et réponses HTTP sont envoyées. QUIC garantie l’ordre des bytes dans un même stream mais ne garantie pas d’ordre entre les différents streams. Ce comportement nécessite la création d’un nouvel algorithme de compression qui est appelé QPACK. Ce nouvel algorithme résout le problème mais nécessite des changements sur la couche application. 

En plus de cela, certaines fonctionnalités d’HTTP/2 (comme le contrôle pour chaque flux) sera géré par QUIC et n’aura donc plus besoin d’être géré par le protocole HTTP.

## Les limites de l’HTTP/3

Le problème le plus important auquel le protocole QUIC est confronté est la sécurité. Bien que l'authentification et le chiffrement fournissent une méthode fiable, cela pose tout de même de nouveaux problèmes. Les entêtes des paquets QUIC contiennent des informations de texte moins claires que ceux de TCP. La régulation du trafic, ou la gestion du réseau deviennent plus dur à gérer avec des connexions QUIC. Les opérateurs de réseau et les fabricants de pare-feu ont donc du mal à garantir la qualité de leur produit. 

Un autre problème concerne le contrôle de l’encombrement sur les réseaux. Ce contrôle se fait de manière automatique pour QUIC mais peut entraîner dans certains cas des taux de transmissions plus faibles qu’avec TCP.

## Conclusion

En conclusion, HTTP/3 permettra de transmettre des données plus rapidement grâce à un nouveau protocole sur la couche transport. Google a mis en pratique le protocole QUIC depuis 2015 et a estimé un gain de temps de 8 à 15% des temps de chargement des pages web. L’HTTP/3 devrait bientôt rentrer dans la norme comme l’a récemment annoncé L'IETF (**Internet Engineering Task Force**) et il est déjà possible de l’activer la plupart des navigateurs. 

### Sources 

- https://www.phonandroid.com/http-3-tout-savoir-sur-le-nouveau-protocole-qui-va-accelerer-le-web.html
- https://kinsta.com/fr/blog/http3/#
- https://leblogducodeur.fr/la-difference-entre-udp-et-tcp/
- https://www.ionos.fr/digitalguide/hebergement/aspects-techniques/quic/
- https://blog.cloudflare.com/http3-the-past-present-and-future/
- https://www.cloudflare.com/learning/ssl/what-happens-in-a-tls-handshake/
- https://www.fastly.com/blog/quic-handshake-tls-compression-certificates-extension-study

